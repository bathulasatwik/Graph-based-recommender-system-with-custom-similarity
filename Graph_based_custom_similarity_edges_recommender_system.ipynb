{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDi24F9CWLtO"
      },
      "id": "TDi24F9CWLtO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################################################################################################"
      ],
      "metadata": {
        "id": "5OTvCwa-WLwB"
      },
      "id": "5OTvCwa-WLwB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a537566d-52bf-4eaa-9fba-2db51665f7f9",
      "metadata": {
        "id": "a537566d-52bf-4eaa-9fba-2db51665f7f9",
        "outputId": "b5fe1291-111f-47c5-85bb-4a1a12e5980d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User-Item Matrix before GCN:\n",
            " item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
            "user_id                                                              ...   \n",
            "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
            "2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n",
            "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
            "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
            "5         4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
            "\n",
            "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
            "user_id                                                              \n",
            "1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "\n",
            "[5 rows x 1682 columns]\n",
            "Any NaN in similarity matrix: False\n",
            "Any NaN in edge weights: tensor(False)\n",
            "Epoch 0, Loss: 13.735160827636719\n",
            "Epoch 10, Loss: 3.8542418479919434\n",
            "Epoch 20, Loss: 3.2745108604431152\n",
            "Epoch 30, Loss: 3.0636277198791504\n",
            "Epoch 40, Loss: 2.927325963973999\n",
            "Epoch 50, Loss: 2.8500468730926514\n",
            "Epoch 60, Loss: 2.776137113571167\n",
            "Epoch 70, Loss: 2.704547166824341\n",
            "Epoch 80, Loss: 2.633363723754883\n",
            "Epoch 90, Loss: 2.5629069805145264\n",
            "Epoch 100, Loss: 2.492668628692627\n",
            "Epoch 110, Loss: 2.4229745864868164\n",
            "Epoch 120, Loss: 2.3540749549865723\n",
            "Epoch 130, Loss: 2.2861411571502686\n",
            "Epoch 140, Loss: 2.219315528869629\n",
            "Epoch 150, Loss: 2.1537013053894043\n",
            "Epoch 160, Loss: 2.0893630981445312\n",
            "Epoch 170, Loss: 2.0263521671295166\n",
            "Epoch 180, Loss: 1.9647043943405151\n",
            "Epoch 190, Loss: 1.9044402837753296\n",
            "Epoch 200, Loss: 1.8455606698989868\n",
            "Epoch 210, Loss: 1.788050889968872\n",
            "Epoch 220, Loss: 1.7318873405456543\n",
            "Epoch 230, Loss: 1.6770397424697876\n",
            "Epoch 240, Loss: 1.6234699487686157\n",
            "Epoch 250, Loss: 1.5711326599121094\n",
            "Epoch 260, Loss: 1.5203291177749634\n",
            "Epoch 270, Loss: 1.4851837158203125\n",
            "Epoch 280, Loss: 1.4290766716003418\n",
            "Epoch 290, Loss: 1.3860372304916382\n",
            "Epoch 300, Loss: 1.3446978330612183\n",
            "Epoch 310, Loss: 1.312479019165039\n",
            "Epoch 320, Loss: 1.2900135517120361\n",
            "Epoch 330, Loss: 1.548235297203064\n",
            "Epoch 340, Loss: 1.3504862785339355\n",
            "Epoch 350, Loss: 1.2080861330032349\n",
            "Epoch 360, Loss: 1.1835989952087402\n",
            "Epoch 370, Loss: 1.158456563949585\n",
            "Epoch 380, Loss: 1.1307460069656372\n",
            "Epoch 390, Loss: 1.1172633171081543\n",
            "Epoch 400, Loss: 1.097823143005371\n",
            "Epoch 410, Loss: 1.0864804983139038\n",
            "Epoch 420, Loss: 1.0747294425964355\n",
            "Epoch 430, Loss: 1.0678377151489258\n",
            "Epoch 440, Loss: 1.0458879470825195\n",
            "Epoch 450, Loss: 1.0353376865386963\n",
            "Epoch 460, Loss: 1.0485690832138062\n",
            "Epoch 470, Loss: 1.0291727781295776\n",
            "Epoch 480, Loss: 1.0216279029846191\n",
            "Epoch 490, Loss: 1.0170174837112427\n",
            "User-Item Matrix after GCN:\n",
            " item_id      1         2         3         4         5         6         7     \\\n",
            "user_id                                                                         \n",
            "1        5.000000  3.000000  4.000000  3.000000  3.000000  5.000000  4.000000   \n",
            "2        4.000000  3.138300  2.995719  3.483465  3.196171  3.477932  3.765673   \n",
            "3        3.798166  3.100736  2.968449  3.455488  3.167139  3.449922  3.712547   \n",
            "4        3.872135  3.139796  2.996911  3.484746  3.197361  3.479163  3.767861   \n",
            "5        4.000000  3.000000  3.022011  3.512135  3.221965  3.505120  3.813038   \n",
            "...           ...       ...       ...       ...       ...       ...       ...   \n",
            "939      3.777789  3.092538  2.979121  3.475583  3.166664  3.461862  3.712510   \n",
            "940      3.783461  3.096020  2.984860  2.000000  3.170490  3.467943  4.000000   \n",
            "941      5.000000  3.098617  2.988856  3.488502  3.173240  3.472176  4.000000   \n",
            "942      3.777355  3.092264  2.978648  3.474942  3.166355  3.461359  3.711937   \n",
            "943      3.770448  5.000000  2.968144  3.460278  3.160210  3.450155  3.700330   \n",
            "\n",
            "item_id      8         9         10    ...      1673      1674      1675  \\\n",
            "user_id                                ...                                 \n",
            "1        1.000000  5.000000  3.000000  ...  5.000000  5.000000  5.000000   \n",
            "2        3.918165  3.858488  2.000000  ...  3.161453  4.227241  3.158627   \n",
            "3        3.875731  3.800334  3.667501  ...  3.050265  4.063166  3.049681   \n",
            "4        3.920002  3.860845  3.697274  ...  3.165703  4.233349  3.162780   \n",
            "5        3.958399  3.909145  3.723797  ...  3.250860  4.355193  3.245894   \n",
            "...           ...       ...       ...  ...       ...       ...       ...   \n",
            "939      3.888646  5.000000  3.680202  ...  2.997652  3.964213  2.996311   \n",
            "940      5.000000  3.000000  3.686496  ...  3.002506  3.967262  3.000714   \n",
            "941      3.902611  3.805295  3.690873  ...  3.006572  3.970550  3.004463   \n",
            "942      3.887964  3.793359  3.679678  ...  2.997315  3.964074  2.996011   \n",
            "943      3.873200  3.000000  3.668042  ...  2.995373  3.970255  2.994877   \n",
            "\n",
            "item_id      1676      1677      1678      1679      1680      1681      1682  \n",
            "user_id                                                                        \n",
            "1        4.379747  5.000000  1.945337  5.000000  4.446529  5.000000  5.000000  \n",
            "2        2.105410  3.149552  1.033645  3.181042  2.108253  2.889037  3.192678  \n",
            "3        2.029114  3.044900  1.011285  3.058107  2.037588  2.776329  3.065095  \n",
            "4        2.108220  3.153582  1.034557  3.185597  2.110939  2.893113  3.197404  \n",
            "5        2.163727  3.234613  1.053303  3.275835  2.164689  2.973193  3.291074  \n",
            "...           ...       ...       ...       ...       ...       ...       ...  \n",
            "939      1.976671  3.000284  1.009770  2.978089  2.002117  2.688081  2.982136  \n",
            "940      1.976857  3.005798  1.012493  2.979241  2.004812  2.686268  2.983351  \n",
            "941      1.977561  3.010250  1.014467  2.980962  2.007137  2.685948  2.985142  \n",
            "942      1.976716  2.999888  1.009552  2.978083  2.001940  2.688327  2.982128  \n",
            "943      1.982331  2.995964  1.005305  2.985218  2.001561  2.701196  2.989496  \n",
            "\n",
            "[943 rows x 1682 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from scipy.special import softmax\n",
        "from scipy.stats import entropy\n",
        "\n",
        "url = 'http://files.grouplens.org/datasets/movielens/ml-100k/u.data'\n",
        "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "\n",
        "df = pd.read_csv(url, sep='\\t', names=columns)\n",
        "\n",
        "df.drop('timestamp', axis=1, inplace=True)\n",
        "\n",
        "# Creating a user-item matrix\n",
        "user_item_matrix = df.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
        "\n",
        "print(\"User-Item Matrix before GCN:\\n\", user_item_matrix.head())\n",
        "\n",
        "features = torch.tensor(user_item_matrix.values, dtype=torch.float)\n",
        "\n",
        "# custom similarity metric\n",
        "def stable_softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "def custom_similarity(v1, v2):\n",
        "    epsilon = 1e-8  # Small value to avoid division by zero\n",
        "    v1 = stable_softmax(v1)\n",
        "    v2 = stable_softmax(v2)\n",
        "\n",
        "    if np.isnan(v1).any() or np.isnan(v2).any():\n",
        "        print(\"NaN detected in softmax output\")\n",
        "        return np.nan\n",
        "\n",
        "    indices_v1 = np.arange(1, len(v1) + 1)\n",
        "    v1_exp = v1 * np.exp(v1 * indices_v1)\n",
        "\n",
        "    indices_v2 = np.arange(1, len(v2) + 1)\n",
        "    v2_exp = v2 * np.exp(v2 * indices_v2)\n",
        "\n",
        "    if np.isnan(v1_exp).any() or np.isnan(v2_exp).any():\n",
        "        print(\"NaN detected in exponential transformation\")\n",
        "        return np.nan\n",
        "\n",
        "    joint_distribution = np.outer(v1_exp, v2_exp)\n",
        "    v1_flat = v1_exp.flatten()\n",
        "    v2_flat = v2_exp.flatten()\n",
        "    joint_flat = joint_distribution.flatten()\n",
        "\n",
        "    H_v1 = entropy(v1_flat + epsilon)  # Add epsilon to avoid log(0)\n",
        "    H_v2 = entropy(v2_flat + epsilon)  # Add epsilon to avoid log(0)\n",
        "\n",
        "    def sum_exponentials_metric(a, b):\n",
        "        return np.exp(a) + np.exp(b)\n",
        "\n",
        "    return sum_exponentials_metric(H_v1, H_v2)\n",
        "\n",
        "num_users = user_item_matrix.shape[0]\n",
        "similarity_matrix = np.zeros((num_users, num_users))\n",
        "\n",
        "for i in range(num_users):\n",
        "    for j in range(num_users):\n",
        "        if i != j:\n",
        "            similarity_matrix[i, j] = custom_similarity(user_item_matrix.iloc[i].values, user_item_matrix.iloc[j].values)\n",
        "\n",
        "# Checking for any NaN values in the similarity matrix\n",
        "print(\"Any NaN in similarity matrix:\", np.isnan(similarity_matrix).any())\n",
        "\n",
        "edge_index = []\n",
        "edge_weight = []\n",
        "\n",
        "for i in range(num_users):\n",
        "    for j in range(num_users):\n",
        "        if i != j:  # to Avoid self-loops for simplicity\n",
        "            edge_index.append([i, j])\n",
        "            edge_weight.append(similarity_matrix[i, j])\n",
        "\n",
        "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "edge_weight = torch.tensor(edge_weight, dtype=torch.float)\n",
        "\n",
        "# Checking for any NaN values in edge weights\n",
        "print(\"Any NaN in edge weights:\", torch.isnan(edge_weight).any())\n",
        "\n",
        "# Defining the GCN model\n",
        "class DeeperWeightedGCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DeeperWeightedGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 64, normalize=True, add_self_loops=False)\n",
        "        self.conv2 = GCNConv(64, 32, normalize=True, add_self_loops=False)\n",
        "        self.conv3 = GCNConv(32, 16, normalize=True, add_self_loops=False)\n",
        "        self.conv4 = GCNConv(16, out_channels, normalize=True, add_self_loops=False)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        # First Convolutional Layer\n",
        "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
        "        if torch.isnan(x).any():\n",
        "            print(\"NaN values after conv1\")\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Second Convolutional Layer\n",
        "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
        "        if torch.isnan(x).any():\n",
        "            print(\"NaN values after conv2\")\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Third Convolutional Layer\n",
        "        x = self.conv3(x, edge_index, edge_weight=edge_weight)\n",
        "        if torch.isnan(x).any():\n",
        "            print(\"NaN values after conv3\")\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Fourth Convolutional Layer (Final)\n",
        "        x = self.conv4(x, edge_index, edge_weight=edge_weight)\n",
        "        if torch.isnan(x).any():\n",
        "            print(\"NaN values after conv4\")\n",
        "\n",
        "        return x\n",
        "model = DeeperWeightedGCN(features.size(1), features.size(1))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "data = Data(x=features, edge_index=edge_index, edge_attr=edge_weight)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(500):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index, data.edge_attr)\n",
        "\n",
        "    if torch.isnan(out).any():\n",
        "        print(\"NaN values in the output at epoch\", epoch)\n",
        "        print(pd.DataFrame(out.detach().numpy(), index=user_item_matrix.index, columns=user_item_matrix.columns))  # Detach the tensor before converting to numpy\n",
        "        break\n",
        "\n",
        "    loss = criterion(out[data.x != 0], data.x[data.x != 0])\n",
        "\n",
        "    if torch.isnan(loss).any():\n",
        "        print(\"NaN values in the loss at epoch\", epoch)\n",
        "        break\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "# Predicting the ratings\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data.x, data.edge_index, data.edge_attr)\n",
        "\n",
        "# Applying the constraint: clip the values between 1 and 5\n",
        "out = torch.clamp(out, min=1.0, max=5.0)\n",
        "\n",
        "predicted_ratings = pd.DataFrame(out.numpy(), index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
        "\n",
        "for user in user_item_matrix.index:\n",
        "    for movie in user_item_matrix.columns:\n",
        "        if user_item_matrix.at[user, movie] == 0:\n",
        "            user_item_matrix.at[user, movie] = predicted_ratings.at[user, movie]\n",
        "\n",
        "print(\"User-Item Matrix after GCN:\\n\", user_item_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CwKj-ob7Vnk6"
      },
      "id": "CwKj-ob7Vnk6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18ab15c-c381-4f7f-b220-6297940ef588",
      "metadata": {
        "id": "c18ab15c-c381-4f7f-b220-6297940ef588"
      },
      "outputs": [],
      "source": [
        "after = np.array(user_item_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ba7943-8a3c-475d-9004-6b2dd0a28e7f",
      "metadata": {
        "id": "d0ba7943-8a3c-475d-9004-6b2dd0a28e7f"
      },
      "outputs": [],
      "source": [
        "before = np.array(user_item_matrix_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ee4aca-9cde-4ec6-b961-9fec29f97c39",
      "metadata": {
        "id": "a8ee4aca-9cde-4ec6-b961-9fec29f97c39",
        "outputId": "906a1472-7599-479a-91f8-d839bc1ee854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Precision@10 across all users: 0.7799575821845165\n"
          ]
        }
      ],
      "source": [
        "# for exponential sum\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def precision_at_k(predictions, actuals, k):\n",
        "    top_k_pred = np.argsort(predictions)[-k:]\n",
        "    relevant_items = np.nonzero(actuals)[0]\n",
        "    precision = len(set(top_k_pred).intersection(set(relevant_items))) / k\n",
        "    return precision\n",
        "\n",
        "k = 10\n",
        "num_users = before.shape[0]\n",
        "total_precision = 0\n",
        "\n",
        "for user_id in range(num_users):\n",
        "    precision = precision_at_k(after[user_id], before[user_id], k)\n",
        "    total_precision += precision\n",
        "\n",
        "average_precision = total_precision / num_users\n",
        "\n",
        "print(f\"Average Precision@{k} across all users: {average_precision}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "johtE7U3WG7s"
      },
      "id": "johtE7U3WG7s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################################################################################################################################"
      ],
      "metadata": {
        "id": "Q8zl5Z1hWG-n"
      },
      "id": "Q8zl5Z1hWG-n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqhfmKdNWHBP"
      },
      "id": "pqhfmKdNWHBP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8afc033-128f-4be4-92ad-e622a1024d3b",
      "metadata": {
        "id": "f8afc033-128f-4be4-92ad-e622a1024d3b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}